{
    "inference.model": "codellama:7b-code-q6_K"
}